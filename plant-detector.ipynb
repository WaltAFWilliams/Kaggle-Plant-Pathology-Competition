{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dependencies"},{"metadata":{"_uuid":"cf7a46c1-71d6-42ee-96df-81178af00285","_cell_guid":"def080b9-21b3-4b4b-909d-89abb8794c37","trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install -q efficientnet # Efficientnet not supported in tensorflow yet\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.linear_model import LogisticRegression\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.models import save_model, Sequential, load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Kaggle TPU Activation"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# Data access\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(\"plant-pathology-2020-fgvc7\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"728cbdc3-5ab8-4cd0-b5fe-b9e3189ad668","_cell_guid":"088cff2f-110c-4513-8bdd-84b3debd7b9d","trusted":true},"cell_type":"code","source":"# Configs\nAUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 800","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"_uuid":"0b5b9b09-14b4-4128-ae94-148311983438","_cell_guid":"9b5d5c14-0d17-4f12-90fc-050bccc3552e","trusted":true},"cell_type":"code","source":"# Show random set of images\ndef show_images_in(path, n=16):\n    files_to_show = os.listdir(path)[:n]\n    assert files_to_show[0].endswith((\".jpg\",\".jpeg\",\".png\"))\n    np.random.shuffle(files_to_show)\n    img_paths = [os.path.join(path,file) for file in files_to_show]\n    plt.figure(figsize=(12,12))\n    for i in range(n):\n        img = plt.imread(img_paths[i])\n        plt.subplot(4,4,i+1)\n        plt.imshow(img)\n    plt.tight_layout()\nshow_images_in(\"../input/plant-pathology-2020-fgvc7/images/\",n=16)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5b95f64-f822-45e0-bde7-31723614857e","_cell_guid":"3d222e21-2b83-4b23-81e9-7f3edc182b07","trusted":true},"cell_type":"code","source":"# Learning rate scheduler\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlr_schedule = LearningRateScheduler(lrfn, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n    # Read file as binary\n    bits = tf.io.read_file(filename)\n    # Decode binary file into pixel values\n    image = tf.image.decode_jpeg(bits, channels=3)\n    # Normalize pixel values (change into floats in [0,1])\n    image = tf.cast(image, tf.float32) / 255.0\n    # Resize image to correct size\n    image = tf.image.resize(image, image_size)\n \n    if label is None: # Used for testing data, label is not given in dataframe because of competition\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    # Data augmentation, nothing fancy here.\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n\n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n\n# Turning filepaths into absolute paths in our dataframe\ntrain_paths = train.image_id.apply(lambda x: GCS_DS_PATH + \"/images/\" + x +\".jpg\").values\ntest_paths = test.image_id.apply(lambda x: GCS_DS_PATH + \"/images/\" + x +\".jpg\").values\ntrain_labels = train.loc[:, 'healthy':].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the dataset objects for TPU feeding\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(read_image, num_parallel_calls=AUTO)\n    .cache()\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(IMG_SIZE, reshuffle_each_iteration=True)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(read_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(read_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"600b9412-e723-403a-bfad-5db33b2540ea","_cell_guid":"aa9e5d5c-f89e-4c66-8f14-122d3e6c282a","trusted":true},"cell_type":"markdown","source":"# Training"},{"metadata":{"_uuid":"c049f979-bad0-4421-9153-4110109daa3c","_cell_guid":"26d33887-f7c9-4b47-891c-d5131888266a","trusted":true},"cell_type":"code","source":"arrs = [] # For model ensemebling. After every trained model, we append predictions here\n\n# Train 2 EfficientNetB7s and append predictions to arr\nfor i in range(2):\n    with strategy.scope():\n        model = Sequential()\n        base = efn.EfficientNetB7(input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False, weights=\"imagenet\")\n        #base.trainable=False\n        model.add(base)  \n        model.add(Dropout(0.5))\n        model.add(GlobalAvgPool2D())\n        model.add(Dense(4, activation=\"softmax\"))\n        model.compile(optimizer=\"adam\",loss=CategoricalCrossentropy(label_smoothing=0.1), metrics=[\"categorical_accuracy\"])\n        early_stop = EarlyStopping(monitor=\"loss\", patience=8, min_delta=0.01)\n        reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n        H = model.fit(train_dataset, epochs=15,steps_per_epoch=len(train_paths)//BATCH_SIZE, callbacks=[early_stop,lr_schedule])\n        preds = np.array(model.predict(test_dataset))\n        arrs.append(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train 2 IncepResNets and append predictions to arr\nfor i in range(2):\n    with strategy.scope():\n        model = Sequential()\n        base = InceptionResNetV2(input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False, weights=\"imagenet\")\n        model.add(base)\n        model.add(Dropout(0.5))\n        model.add(GlobalAveragePooling2D())\n        model.add(Dense(4, activation=\"softmax\"))\n        model.compile(optimizer=\"adam\",loss=CategoricalCrossentropy(label_smoothing=0.1), metrics=[\"categorical_accuracy\"])\n        early_stop = EarlyStopping(monitor=\"loss\", min_delta=.01, patience=8)\n        H = model.fit(train_dataset, epochs=15,steps_per_epoch=len(train_paths)//BATCH_SIZE, callbacks=[early_stop,lr_schedule])\n        preds = model.predict(test_dataset)\n        # Predictions\n        preds = np.array(model.predict(test_dataset))\n        arrs.append(preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inference function, averages all predictions then creates a submission dataframe for competition\ndef make_new_preds(arr_list, NUM_OLD_MODELS=1, submission_name=\"new_preds.csv\"):\n    arrs = np.asarray(arr_list)\n    avg = np.sum(arrs, axis=0)\n    old_preds = pd.read_csv(\"../input/incesres/2IncResNets  2EFNB7.csv\").loc[:,\"healthy\":].values * NUM_OLD_MODELS\n    new_preds = (old_preds + avg) / (len(arr_list) + NUM_OLD_MODELS)\n    sub.loc[:,\"healthy\":] = new_preds\n    sub.head()\n    sub.to_csv(submission_name, index=False)\n    \nmake_new_preds(arrs, 4)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}